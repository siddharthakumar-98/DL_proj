{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satellite image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.abspath(''))\n",
    "proj_dir = dir_path + '/Planet/'\n",
    "os.chdir(proj_dir)\n",
    "\n",
    "# Initialize a list to hold processed data\n",
    "processed_data = []\n",
    "\n",
    "# Loop through each subdirectory (site)\n",
    "for site_folder in os.listdir(proj_dir):\n",
    "    if site_folder.startswith('013'):\n",
    "        if 'json' not in site_folder:\n",
    "            site_path = os.path.join(proj_dir, site_folder)\n",
    "            \n",
    "            # Check if the current path is a directory\n",
    "            if os.path.isdir(site_path):\n",
    "                # Load the target data\n",
    "                targets_path = os.path.join(site_path, 'targets.csv')\n",
    "                targets_df = pd.read_csv(targets_path, index_col=[0])\n",
    "                targets_df.index = pd.to_datetime(targets_df.index).date\n",
    "                \n",
    "                # Loop through each .tif file in the subdirectory\n",
    "                for file in os.listdir(site_path):\n",
    "                    if file.endswith('.tif'):\n",
    "                        # Check file size and only include images greater than 25 KB\n",
    "                        size_threshold = 25 * 1024  # 25 KB in bytes\n",
    "                        file_size = os.path.getsize(os.path.join(site_path, file))\n",
    "                        if file_size >= size_threshold:\n",
    "                            # Extract the date from the filename\n",
    "                            date_str = file[:8]  # Assuming the date is the first 8 characters\n",
    "                            date = datetime.strptime(date_str, '%Y%m%d').date()\n",
    "                            \n",
    "                            # Check if the date is in the targets DataFrame\n",
    "                            if date in targets_df.index:\n",
    "                                target_value = targets_df.loc[date, 'turbidity (FNU)']\n",
    "                                \n",
    "                                # Read the .tif file as a 4-dimensional array\n",
    "                                tif_path = os.path.join(site_path, file)\n",
    "                                with rasterio.open(tif_path) as src:\n",
    "                                    raster_array = src.read()  # (bands, width, height)\n",
    "                                \n",
    "                                # Append the data to the processed_data list\n",
    "                                processed_data.append({\n",
    "                                    'site': site_folder,\n",
    "                                    'date': date,\n",
    "                                    'raster': raster_array,\n",
    "                                    'target': target_value\n",
    "                                })\n",
    "\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save processed_data as a pickle file\n",
    "pickle_file_path = 'processed_data.pkl'\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df_test = pd.read_csv('processed_data.csv')\n",
    "processed_data = pd.read_pickle('processed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937533802055165\n"
     ]
    }
   ],
   "source": [
    "num_elements = len(processed_data_pckl[0]['raster'])* len(processed_data_pckl[0]['raster'][1])* len(processed_data_pckl[0]['raster'][2])\n",
    "print(np.count_nonzero(processed_data_pckl[0]['raster']) / num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(processed_data)\n",
    "data.set_index(['site', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
